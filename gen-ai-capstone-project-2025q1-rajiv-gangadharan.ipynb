{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58b2f23e",
   "metadata": {
    "papermill": {
     "duration": 0.006752,
     "end_time": "2025-04-12T20:44:37.292768",
     "exception": false,
     "start_time": "2025-04-12T20:44:37.286016",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Project Information\n",
    "\n",
    "Project Background: Building a Desktop and Laptop Support Agent Assistant with Generative AI\n",
    "\n",
    "## Context\n",
    "\n",
    "In today's oganizations, providing efficient and effective customer support for technical issues related to desktops and laptops is crucial. Customer support agents often deal with a wide range of queries, from basic troubleshooting steps to more complex hardware and software problems. Access to well-structured and easily searchable support documentation is essential for agents to quickly diagnose and resolve customer issues.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af40fa06",
   "metadata": {
    "papermill": {
     "duration": 0.004732,
     "end_time": "2025-04-12T20:44:37.302792",
     "exception": false,
     "start_time": "2025-04-12T20:44:37.298060",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Problem Outline\n",
    "\n",
    "Traditional methods of accessing support documentation can be time-consuming. Agents may need to navigate through lengthy PDF files or knowledge base articles to find the relevant information. This can lead to longer resolution times, increased frustration for both agents and customers, and potentially lower customer satisfaction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c8ef41",
   "metadata": {
    "papermill": {
     "duration": 0.004859,
     "end_time": "2025-04-12T20:44:37.313806",
     "exception": false,
     "start_time": "2025-04-12T20:44:37.308947",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "##  Proposed Solution\n",
    "\n",
    "\n",
    "This project aims to leverage the power of Generative AI to create an intelligent assistant that can enhance the capabilities of customer support agents dealing with desktop and laptop issues. The core idea is to process existing support documentation (in this case, a synthetic PDF file created for this purpose) and enable agents to quickly retrieve relevant information and potentially generate helpful responses or troubleshooting steps based on customer queries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a00a56",
   "metadata": {
    "papermill": {
     "duration": 0.004075,
     "end_time": "2025-04-12T20:44:37.322232",
     "exception": false,
     "start_time": "2025-04-12T20:44:37.318157",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Key Components:\n",
    "\n",
    "## Support Documentation\n",
    "\n",
    "This is the primary dataset. A synthetic PDF file containing common desktop and laptop troubleshooting steps, structured into logical sections (e.g., power issues, display problems, network connectivity, battery issues). This document serves as the knowledge base for the AI assistant.\n",
    "\n",
    "## Generative AI Model\n",
    "\n",
    "A Large Language Model (LLM), _command-r-plus_ from _COHERE_ This model will be used to understand user queries and extract relevant information from the support documentation.\n",
    "\n",
    "## Embedding Model\n",
    "\n",
    "The embedding model used is _embed-english-light-v3.0_ also from _COHERE_. \n",
    "\n",
    "## Vector Store\n",
    "\n",
    "I have used qdrant in this case. \n",
    "\n",
    "## LangChain and Langgraph Framework\n",
    "\n",
    "The LangChain library was used as the framework to connect the LLM with the support documentation. This involved techniques like:\n",
    "\n",
    "* Document Loading: Loading and processing the PDF file.\n",
    "* Text Splitting: Dividing the document into smaller chunks for efficient retrieval.\n",
    "* Vector Embeddings: Creating vector representations of the text chunks to enable semantic search.\n",
    "* Retrieval-Based Question Answering: Using a retrieval mechanism (e.g., a vector store and similarity search) to find relevant sections in the documentation based on the agent's query.\n",
    "* Response Generation: Utilizing the LLM to generate concise and helpful answers or troubleshooting steps based on the retrieved information.\n",
    "\n",
    "For the agent creation and operation, LangGraph was used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830bc6a2",
   "metadata": {
    "papermill": {
     "duration": 0.004135,
     "end_time": "2025-04-12T20:44:37.330565",
     "exception": false,
     "start_time": "2025-04-12T20:44:37.326430",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Demonstration of AI Capabilities\n",
    "\n",
    "In this Capstone Project, the following GenAI capabilities have been demonstrated\n",
    "\n",
    "1. Structured output/JSON mode/controlled generation\n",
    "2. Few-shot prompting\n",
    "3. Document understanding\n",
    "4. Function Calling\n",
    "5. Agents\n",
    "6. Embeddings\n",
    "7. Retrieval augmented generation (RAG)\n",
    "8. Vector search/vector store/vector database\n",
    "9. Grounding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3877b20c",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-12T20:44:37.339969Z",
     "iopub.status.busy": "2025-04-12T20:44:37.339706Z",
     "iopub.status.idle": "2025-04-12T20:44:39.027257Z",
     "shell.execute_reply": "2025-04-12T20:44:39.026348Z"
    },
    "papermill": {
     "duration": 1.693701,
     "end_time": "2025-04-12T20:44:39.028499",
     "exception": false,
     "start_time": "2025-04-12T20:44:37.334798",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../input/pm-80499167-at-04-12-2025-20-44-04/__script__.py\n",
      "../input/pm-80499167-at-04-12-2025-20-44-04/__results__.html\n",
      "../input/pm-80499167-at-04-12-2025-20-44-04/input_requirements.txt\n",
      "../input/pm-80499167-at-04-12-2025-20-44-04/__script__.ipynb\n",
      "../input/pm-80499167-at-04-12-2025-20-44-04/__output__.json\n",
      "../input/pm-80499167-at-04-12-2025-20-44-04/custom.css\n",
      "../input/support-documentation/support_documentation.pdf\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('../input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "218e4f69",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T20:44:39.038623Z",
     "iopub.status.busy": "2025-04-12T20:44:39.038325Z",
     "iopub.status.idle": "2025-04-12T20:46:45.232334Z",
     "shell.execute_reply": "2025-04-12T20:46:45.231434Z"
    },
    "papermill": {
     "duration": 126.200354,
     "end_time": "2025-04-12T20:46:45.233733",
     "exception": false,
     "start_time": "2025-04-12T20:44:39.033379",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m423.3/423.3 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m39.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m96.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m340.6/340.6 kB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "cuml-cu12 25.2.1 requires pylibraft-cu12==25.2.*, which is not installed.\r\n",
      "cuvs-cu12 25.2.1 requires pylibraft-cu12==25.2.*, which is not installed.\r\n",
      "pylibcugraph-cu12 24.12.0 requires pylibraft-cu12==24.12.*, which is not installed.\r\n",
      "pylibcugraph-cu12 24.12.0 requires rmm-cu12==24.12.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m306.7/306.7 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m62.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m81.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "google-cloud-translate 3.12.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.29.4 which is incompatible.\r\n",
      "google-api-core 1.34.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<4.0.0dev,>=3.19.5, but you have protobuf 5.29.4 which is incompatible.\r\n",
      "google-spark-connect 0.5.2 requires google-api-core>=2.19.1, but you have google-api-core 1.34.1 which is incompatible.\r\n",
      "pandas-gbq 0.26.1 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\r\n",
      "bigframes 1.36.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\r\n",
      "google-cloud-bigtable 2.28.1 requires google-api-core[grpc]<3.0.0dev,>=2.16.0, but you have google-api-core 1.34.1 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.2/259.2 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m64.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m86.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip uninstall -qqy pylibraft-cu12\n",
    "!pip uninstall -qqy jupyterlab  # Remove unused packages from Kaggle's base image that conflict\n",
    "!pip install -qqU langchain-core langchain-text-splitters langchain \n",
    "!pip install -qqU transformers sentence-transformers pypdf langchain\n",
    "!pip install -qqU qdrant-client\n",
    "!pip install -qqU \"langchain[cohere]\"\n",
    "!pip install -qqU langchain-community\n",
    "!pip install -qqU \"langchain-qdrant\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffa97fab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T20:46:45.282330Z",
     "iopub.status.busy": "2025-04-12T20:46:45.281997Z",
     "iopub.status.idle": "2025-04-12T20:46:45.709151Z",
     "shell.execute_reply": "2025-04-12T20:46:45.708187Z"
    },
    "papermill": {
     "duration": 0.452647,
     "end_time": "2025-04-12T20:46:45.710689",
     "exception": false,
     "start_time": "2025-04-12T20:46:45.258042",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "CO_API_KEY = UserSecretsClient().get_secret(\"COHERE_API_KEY\")\n",
    "QDRANT_API_KEY = UserSecretsClient().get_secret(\"QDRANT_CLOUD_API_KEY\")\n",
    "QDRANT_CLOUD_HOST = UserSecretsClient().get_secret(\"QDRANT_CLOUD_HOST\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "063df4c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T20:46:45.757431Z",
     "iopub.status.busy": "2025-04-12T20:46:45.757175Z",
     "iopub.status.idle": "2025-04-12T20:46:48.674043Z",
     "shell.execute_reply": "2025-04-12T20:46:48.673246Z"
    },
    "papermill": {
     "duration": 2.941607,
     "end_time": "2025-04-12T20:46:48.675421",
     "exception": false,
     "start_time": "2025-04-12T20:46:45.733814",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "model = init_chat_model(\"command-r-plus\", \n",
    "                        model_provider=\"cohere\",\n",
    "                        cohere_api_key=CO_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1481df3a",
   "metadata": {
    "papermill": {
     "duration": 0.022351,
     "end_time": "2025-04-12T20:46:48.721647",
     "exception": false,
     "start_time": "2025-04-12T20:46:48.699296",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Define loader, text splitters \n",
    "The next step is to get the loader and the text spliters so that we can load\n",
    "and split the text document to get into a array of Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5356783",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T20:46:48.813639Z",
     "iopub.status.busy": "2025-04-12T20:46:48.813183Z",
     "iopub.status.idle": "2025-04-12T20:46:48.825400Z",
     "shell.execute_reply": "2025-04-12T20:46:48.824888Z"
    },
    "papermill": {
     "duration": 0.037201,
     "end_time": "2025-04-12T20:46:48.826535",
     "exception": false,
     "start_time": "2025-04-12T20:46:48.789334",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain_community.document_loaders.directory import DirectoryLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.documents import Document"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52599b1",
   "metadata": {
    "papermill": {
     "duration": 0.022267,
     "end_time": "2025-04-12T20:46:48.873717",
     "exception": false,
     "start_time": "2025-04-12T20:46:48.851450",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The code below loads and splits PDF files into manageable chunks using the\n",
    "DirectoryLoader and RecursiveCharacterTextSplitter classes from the PyMuPDF library.\n",
    "\n",
    "First, a DirectoryLoader object named `loader` is created with the following\n",
    "parameters:\n",
    "- `path=\"..\"`: The path to the directory containing the PDF files.\n",
    "- `glob=\"**/*.pdf\"`: A glob pattern specifying that only PDF files should be loaded.\n",
    "- `recursive=True`: A flag indicating that the search for PDF files should be\n",
    "performed recursively within subdirectories.\n",
    "- `show_progress=True`: A flag indicating whether a progress bar should be displayed\n",
    "during file loading.\n",
    "\n",
    "Next, a RecursiveCharacterTextSplitter object named `text_splitter` is created with\n",
    "the following parameters:\n",
    "- `chunk_size=50`: The maximum number of characters to include in each text chunk.\n",
    "- `chunk_overlap=10`: The number of characters that overlap between consecutive\n",
    "chunks.\n",
    "\n",
    "Finally, the code assigns the result of calling the `load_and_split()` method on the\n",
    "`loader` object to a variable named `docs`. This method loads all PDF files from the\n",
    "specified directory and its subdirectories, splits each loaded file into text chunks\n",
    "using the `text_splitter`, and returns a list of Document objects representing the\n",
    "split PDF files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d955855a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T20:46:48.920263Z",
     "iopub.status.busy": "2025-04-12T20:46:48.920016Z",
     "iopub.status.idle": "2025-04-12T20:46:49.228142Z",
     "shell.execute_reply": "2025-04-12T20:46:49.227606Z"
    },
    "papermill": {
     "duration": 0.333317,
     "end_time": "2025-04-12T20:46:49.229486",
     "exception": false,
     "start_time": "2025-04-12T20:46:48.896169",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFDirectoryLoader\n",
    "loader = PyPDFDirectoryLoader(path=\"..\", glob=\"**/*.pdf\", \n",
    "                         recursive=True, )\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=50, chunk_overlap=10)\n",
    "docs: Document = loader.load_and_split()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4543ca68",
   "metadata": {
    "papermill": {
     "duration": 0.022356,
     "end_time": "2025-04-12T20:46:49.275454",
     "exception": false,
     "start_time": "2025-04-12T20:46:49.253098",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Vector Store\n",
    "\n",
    "At this point, we have to install qdrant for the vector store and the langchain libraries which facilitate the interaction with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43c2a02e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T20:46:49.322186Z",
     "iopub.status.busy": "2025-04-12T20:46:49.321586Z",
     "iopub.status.idle": "2025-04-12T20:46:49.424864Z",
     "shell.execute_reply": "2025-04-12T20:46:49.424370Z"
    },
    "papermill": {
     "duration": 0.127678,
     "end_time": "2025-04-12T20:46:49.426135",
     "exception": false,
     "start_time": "2025-04-12T20:46:49.298457",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_cohere.embeddings import CohereEmbeddings\n",
    "from langchain_cohere.chat_models import ChatCohere\n",
    "\n",
    "embeddings = CohereEmbeddings(model=\"embed-english-light-v3.0\", cohere_api_key=CO_API_KEY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da2abcef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T20:46:49.472928Z",
     "iopub.status.busy": "2025-04-12T20:46:49.472673Z",
     "iopub.status.idle": "2025-04-12T20:46:52.044388Z",
     "shell.execute_reply": "2025-04-12T20:46:52.043764Z"
    },
    "papermill": {
     "duration": 2.596417,
     "end_time": "2025-04-12T20:46:52.045695",
     "exception": false,
     "start_time": "2025-04-12T20:46:49.449278",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_qdrant import Qdrant, QdrantVectorStore\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http.models import Distance, VectorParams\n",
    "\n",
    "assert(QDRANT_CLOUD_HOST != None)\n",
    "\n",
    "\n",
    "vector_store = QdrantVectorStore.from_documents(\n",
    "    docs,\n",
    "    embeddings,\n",
    "    url=QDRANT_CLOUD_HOST,\n",
    "    api_key=QDRANT_API_KEY,\n",
    "    collection_name=\"support_documents\",\n",
    ")\n",
    "\n",
    "retriever = vector_store.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29010860",
   "metadata": {
    "papermill": {
     "duration": 0.022431,
     "end_time": "2025-04-12T20:46:52.091444",
     "exception": false,
     "start_time": "2025-04-12T20:46:52.069013",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Storing Documents into the Vector Store\n",
    "\n",
    "At this point we have the vector store defined and have the retriever ready and \n",
    "the next step is to generate the ids for the documents and load the documents into \n",
    "the vector store. The next step accomplishes that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ffe8764",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T20:46:52.137636Z",
     "iopub.status.busy": "2025-04-12T20:46:52.137125Z",
     "iopub.status.idle": "2025-04-12T20:46:52.407112Z",
     "shell.execute_reply": "2025-04-12T20:46:52.406541Z"
    },
    "papermill": {
     "duration": 0.294335,
     "end_time": "2025-04-12T20:46:52.408424",
     "exception": false,
     "start_time": "2025-04-12T20:46:52.114089",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from uuid import uuid4\n",
    "uuids = [str(uuid4()) for _ in range(len(docs))]\n",
    "doc_ids = vector_store.add_documents(ids = uuids, documents = docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "566d03fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T20:46:52.456633Z",
     "iopub.status.busy": "2025-04-12T20:46:52.456382Z",
     "iopub.status.idle": "2025-04-12T20:46:52.461300Z",
     "shell.execute_reply": "2025-04-12T20:46:52.460698Z"
    },
    "papermill": {
     "duration": 0.03013,
     "end_time": "2025-04-12T20:46:52.462294",
     "exception": false,
     "start_time": "2025-04-12T20:46:52.432164",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['c89815f5-b576-468d-8c26-d2999704a1ed',\n",
       " '072e2507-19ac-4122-94ec-cd47832c749e',\n",
       " 'ab986bad-a6e6-4d38-9895-2d7063a9b260']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The following will give us the doc_ids which are loaded\n",
    "doc_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5ae84ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T20:46:52.509204Z",
     "iopub.status.busy": "2025-04-12T20:46:52.509003Z",
     "iopub.status.idle": "2025-04-12T20:46:52.742120Z",
     "shell.execute_reply": "2025-04-12T20:46:52.741651Z"
    },
    "papermill": {
     "duration": 0.257382,
     "end_time": "2025-04-12T20:46:52.743317",
     "exception": false,
     "start_time": "2025-04-12T20:46:52.485935",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test the similarity search \n",
    "documents = vector_store.similarity_search(\"Why is my mouse not working\", k=2, )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9901f262",
   "metadata": {
    "papermill": {
     "duration": 0.023052,
     "end_time": "2025-04-12T20:46:52.790423",
     "exception": false,
     "start_time": "2025-04-12T20:46:52.767371",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "27d475cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T20:46:52.837521Z",
     "iopub.status.busy": "2025-04-12T20:46:52.837315Z",
     "iopub.status.idle": "2025-04-12T20:46:52.942075Z",
     "shell.execute_reply": "2025-04-12T20:46:52.941396Z"
    },
    "papermill": {
     "duration": 0.129761,
     "end_time": "2025-04-12T20:46:52.943302",
     "exception": false,
     "start_time": "2025-04-12T20:46:52.813541",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm = ChatCohere(model=\"command-r-plus\", cohere_api_key=CO_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb2af67",
   "metadata": {
    "papermill": {
     "duration": 0.022936,
     "end_time": "2025-04-12T20:46:52.989392",
     "exception": false,
     "start_time": "2025-04-12T20:46:52.966456",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Few Shot Prompting\n",
    "\n",
    "This demonstrates _few-shot prompting_ by using a retrieval prompt that takes a context and question as input, then retrieves relevant documents to generate an answer.\n",
    "\n",
    "The AI agent iterates through a list of questions, each time retrieving the necessary documents based on the context and the user's question. This allows the AI to learn from only a few examples (the context and related questions), which is characteristic of few-shot prompting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b71be1e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T20:46:53.035937Z",
     "iopub.status.busy": "2025-04-12T20:46:53.035703Z",
     "iopub.status.idle": "2025-04-12T20:46:53.039441Z",
     "shell.execute_reply": "2025-04-12T20:46:53.038932Z"
    },
    "papermill": {
     "duration": 0.028237,
     "end_time": "2025-04-12T20:46:53.040503",
     "exception": false,
     "start_time": "2025-04-12T20:46:53.012266",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "retrieval_prompt = ChatPromptTemplate.from_template(\n",
    "    \n",
    "    \"\"\"Answer the user's question based on the context provided below:\n",
    "    \n",
    "    Context:\n",
    "    {context}\n",
    "\n",
    "    If you are unable to answer based on the document then say \"I do not have that\n",
    "    information with me.\" else provide step by step, numbered action items to solve \n",
    "    the problem.\n",
    "    \n",
    "    Question: {question}\n",
    "    \n",
    "    Answer:\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5263183b",
   "metadata": {
    "papermill": {
     "duration": 0.02244,
     "end_time": "2025-04-12T20:46:53.086322",
     "exception": false,
     "start_time": "2025-04-12T20:46:53.063882",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Constructing the Agent Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "97b18b34",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T20:46:53.133890Z",
     "iopub.status.busy": "2025-04-12T20:46:53.133246Z",
     "iopub.status.idle": "2025-04-12T20:46:57.145765Z",
     "shell.execute_reply": "2025-04-12T20:46:57.145021Z"
    },
    "papermill": {
     "duration": 4.037626,
     "end_time": "2025-04-12T20:46:57.147176",
     "exception": false,
     "start_time": "2025-04-12T20:46:53.109550",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.7/144.7 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.2/47.2 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.6/223.6 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "# Installing LangGraph Libraries\n",
    "\n",
    "!pip  install -Uqq langgraph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734ad0ef",
   "metadata": {
    "papermill": {
     "duration": 0.024834,
     "end_time": "2025-04-12T20:46:57.196126",
     "exception": false,
     "start_time": "2025-04-12T20:46:57.171292",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Testing the Retriever\n",
    "\n",
    "### Creating the State Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd8b2fa1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T20:46:57.245297Z",
     "iopub.status.busy": "2025-04-12T20:46:57.244582Z",
     "iopub.status.idle": "2025-04-12T20:46:57.297954Z",
     "shell.execute_reply": "2025-04-12T20:46:57.297464Z"
    },
    "papermill": {
     "duration": 0.078928,
     "end_time": "2025-04-12T20:46:57.298974",
     "exception": false,
     "start_time": "2025-04-12T20:46:57.220046",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Let's do the agent now\n",
    "from typing import TypedDict, Dict\n",
    "class AgentState(TypedDict):\n",
    "    keys: Dict[str, any]\n",
    "\n",
    "# Here we import the Objects which are necessary to construct the graph\n",
    "\n",
    "from langgraph.graph import StateGraph, END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8be0bca4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T20:46:57.347148Z",
     "iopub.status.busy": "2025-04-12T20:46:57.346956Z",
     "iopub.status.idle": "2025-04-12T20:46:57.602471Z",
     "shell.execute_reply": "2025-04-12T20:46:57.601617Z"
    },
    "papermill": {
     "duration": 0.280673,
     "end_time": "2025-04-12T20:46:57.603729",
     "exception": false,
     "start_time": "2025-04-12T20:46:57.323056",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_20/2006024849.py:6: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  retrieved_docs = retriever.get_relevant_documents(question)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state:AgentState = {\"keys\":{}}\n",
    "user_input = \"My mouse is not working, what might be the problem?\"\n",
    "state = {\"keys\": {\"question\": user_input}}\n",
    "retriever = vector_store.as_retriever(embedding=embeddings, k = 2, )\n",
    "question = state[\"keys\"][\"question\"]\n",
    "retrieved_docs = retriever.get_relevant_documents(question)\n",
    "len(retrieved_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65008e6d",
   "metadata": {
    "papermill": {
     "duration": 0.032701,
     "end_time": "2025-04-12T20:46:57.676397",
     "exception": false,
     "start_time": "2025-04-12T20:46:57.643696",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "1. The `retrieve_documents` function takes a state as input, retrieves relevant\n",
    "documents based on the user's question, and returns them in a new state.\n",
    "2. The `generate_response` function takes a state as input, generates a final response\n",
    "using the Cohere model and retrieved context, and returns it in a new state.\n",
    "3. The workflow is created with nodes for retrieving documents and generating a\n",
    "response, as well as edges connecting these nodes.\n",
    "4. The entry point of the workflow is set to the retrieve node.\n",
    "5. Finally, the workflow is compiled into an agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "77b29025",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T20:46:57.723784Z",
     "iopub.status.busy": "2025-04-12T20:46:57.723531Z",
     "iopub.status.idle": "2025-04-12T20:46:57.727379Z",
     "shell.execute_reply": "2025-04-12T20:46:57.726705Z"
    },
    "papermill": {
     "duration": 0.028795,
     "end_time": "2025-04-12T20:46:57.728578",
     "exception": false,
     "start_time": "2025-04-12T20:46:57.699783",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "context = \",\".join([doc.page_content for doc in retrieved_docs])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea38788",
   "metadata": {
    "papermill": {
     "duration": 0.022988,
     "end_time": "2025-04-12T20:46:57.774810",
     "exception": false,
     "start_time": "2025-04-12T20:46:57.751822",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let's define a state graph-based workflow for an AI agent, which\n",
    "includes three main components: `retrieve_documents`, `generate_response`, and the\n",
    "overall workflow structure.\n",
    "\n",
    "1. The `retrieve_documents` function takes in the current `state` of the agent as its\n",
    "parameter. It retrieves relevant documents based on the user's question using the\n",
    "`embeddings` object and returns an updated state with the retrieved documents' context\n",
    "and the original question.\n",
    "2. The `generate_response` function also accepts the current `state`. It generates a\n",
    "final response using the Cohere model based on the previous 'context' and 'question'\n",
    "stored in the state. The response is then added to the state under the key 'response'.\n",
    "3. The overall workflow, named as per the code block, consists of adding nodes for\n",
    "each function (`\"retrieve\"` corresponding to `retrieve_documents` and `\"generate\"`\n",
    "corresponding to `generate_response`) and connecting them using edges.\n",
    "4. Lastly, an instance of the AI agent is created by compiling the workflow.\n",
    "\n",
    "The workflow structure ensures that the retrieval process occurs first followed by a\n",
    "response generation to provide context-specific answers based on the user's question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "81ccdbac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T20:46:57.821661Z",
     "iopub.status.busy": "2025-04-12T20:46:57.821451Z",
     "iopub.status.idle": "2025-04-12T20:46:57.830494Z",
     "shell.execute_reply": "2025-04-12T20:46:57.829832Z"
    },
    "papermill": {
     "duration": 0.034017,
     "end_time": "2025-04-12T20:46:57.831631",
     "exception": false,
     "start_time": "2025-04-12T20:46:57.797614",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "def retrieve_documents(state) -> AgentState:\n",
    "    \"\"\"Retrieves relevant documents based on the user's question.\"\"\"\n",
    "    question = state[\"keys\"][\"question\"]\n",
    "    if question is None:\n",
    "        raise KeyError(f\"No question in state {question}\")\n",
    "    retriever = vector_store.as_retriever(embedding=embeddings, k = 2, )\n",
    "    retrieved_docs = retriever.get_relevant_documents(question)\n",
    "    context =  {\"context\": \"\\n\\n\".join([doc.page_content for doc in retrieved_docs])}\n",
    "    return {\"keys\":{\"question\":question, \"context\":context,}}\n",
    "\n",
    "def generate_response(state) -> AgentState:\n",
    "    \"\"\"Generates the final response using the Cohere model and retrieved context.\"\"\"\n",
    "    context = state[\"keys\"][\"context\"]\n",
    "    question = state[\"keys\"][\"question\"]\n",
    "    # Use the retrieval_prompt here\n",
    "    response = llm.invoke(retrieval_prompt.format_messages(context=context, question=question))\n",
    "    state[\"keys\"][\"response\"] = response.content\n",
    "    return state\n",
    "\n",
    "# Adding Nodes\n",
    "workflow.add_node(\"retrieve\", retrieve_documents)\n",
    "workflow.add_node(\"generate\", generate_response)\n",
    "\n",
    "# Adding Edges\n",
    "workflow.add_edge(\"retrieve\", \"generate\")\n",
    "workflow.add_edge(\"generate\", END)\n",
    "\n",
    "# Setting the entry point\n",
    "workflow.set_entry_point(\"retrieve\")\n",
    "\n",
    "# Compiling the workflow\n",
    "agent = workflow.compile()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88122e9",
   "metadata": {
    "papermill": {
     "duration": 0.02401,
     "end_time": "2025-04-12T20:46:57.880483",
     "exception": false,
     "start_time": "2025-04-12T20:46:57.856473",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## The Agent State\n",
    "\n",
    "The code below uses a dictionary called `AgentState` to store and manage\n",
    "information about an AI agent's state. In this case, the state includes two keys:\n",
    "'question' and 'context', which are initially empty.\n",
    "\n",
    "Next, a user provides input by assigning a string value `\"My mouse is not working,\n",
    "what might be the problem?\"` to a variable named `user_input`.\n",
    "\n",
    "Then, the code updates the `state` dictionary with the provided user input under the\n",
    "'question' key.\n",
    "\n",
    "The code then calls an `invoke()` function on the AI agent and passes the updated `state` as its argument.\n",
    "\n",
    "Finally, it prints out the response generated by the AI agent based on the given\n",
    "context and question using the key `'response'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1e9b40dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T20:46:57.930007Z",
     "iopub.status.busy": "2025-04-12T20:46:57.929376Z",
     "iopub.status.idle": "2025-04-12T20:47:03.407045Z",
     "shell.execute_reply": "2025-04-12T20:47:03.406529Z"
    },
    "papermill": {
     "duration": 5.504022,
     "end_time": "2025-04-12T20:47:03.408342",
     "exception": false,
     "start_time": "2025-04-12T20:46:57.904320",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "state:AgentState = {\"keys\":{\n",
    "    \"question\":\"\",\n",
    "    \"context\":\"\",\n",
    "}}\n",
    "\n",
    "user_input = \"My mouse is not working, what might be the problem?\"\n",
    "state = {\"keys\": {\"question\": user_input}}\n",
    "state = agent.invoke(state)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a77ef0d",
   "metadata": {
    "papermill": {
     "duration": 0.02295,
     "end_time": "2025-04-12T20:47:03.455064",
     "exception": false,
     "start_time": "2025-04-12T20:47:03.432114",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Response from the Agent\n",
    "\n",
    "The code snippet below gives you the response from the AI Agent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c12e2920",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T20:47:03.502684Z",
     "iopub.status.busy": "2025-04-12T20:47:03.502140Z",
     "iopub.status.idle": "2025-04-12T20:47:03.506391Z",
     "shell.execute_reply": "2025-04-12T20:47:03.505481Z"
    },
    "papermill": {
     "duration": 0.029669,
     "end_time": "2025-04-12T20:47:03.507725",
     "exception": false,
     "start_time": "2025-04-12T20:47:03.478056",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I do not have information about mouse issues in the provided context. However, based on the troubleshooting tips, I can suggest the following general steps: \n",
      "\n",
      "1. Restart your computer: This often resolves temporary software glitches that could be causing the mouse issue. \n",
      "\n",
      "2. Check error messages: Note down any error messages displayed related to your mouse or USB devices for further investigation. \n",
      "\n",
      "3. Gather information: Think about when the problem started and any recent changes you made to your system, such as updating the operating system or installing new software. \n",
      "\n",
      "4. Use the operating system's built-in troubleshooters: Both Windows and macOS have built-in tools for diagnosing common issues, including hardware problems. \n",
      "\n",
      "5. Try a different USB port: Connect your mouse to a different USB port on your computer to ensure the current port is not the issue. \n",
      "\n",
      "6. Try a different mouse: If possible, test with a known working mouse to determine if the issue is specific to your mouse or related to the computer's USB ports or settings. \n",
      "\n",
      "7. Update your operating system: Ensure your operating system is up to date, as there may be bug fixes and improvements that can resolve the issue. \n",
      "\n",
      "8. Check for hardware damage: Inspect the mouse for any physical damage, such as a broken cable or a malfunctioning scroll wheel or sensor. \n",
      "\n",
      "If none of these steps resolve the issue, you may need to contact technical support or consider purchasing a new mouse if the current one is faulty. \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(state[\"keys\"][\"response\"],\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccae2092",
   "metadata": {
    "papermill": {
     "duration": 0.02322,
     "end_time": "2025-04-12T20:47:03.554349",
     "exception": false,
     "start_time": "2025-04-12T20:47:03.531129",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Final Thoughts\n",
    "\n",
    "This implementation can be expanded to support other use cases by simply adding more\n",
    "nodes and edges in the workflow graph or extending `retrieve_documents` and/or\n",
    "`generate_response`.\n",
    "\n",
    "For instance, additional nodes could be created for pre-processing user queries (`\n",
    "preprocess_query`), interpreting retrieved documents (` interpret_documents`), or\n",
    "generating follow-up responses (` generate_followup`). An extended\n",
    "`retrieve_documents` might query multiple document sources simultaneously. Meanwhile,\n",
    "an expanded `generate_response` could generate multiple possible responses and select\n",
    "one at random based on certain criteria.\n",
    "\n",
    "In a nutshell, the workflow structure provides a flexible way to add more complex\n",
    "behavior in steps without changing much of the underlying logic or architecture. This\n",
    "is the strength and promise of state graph-based AI agents: they can be incrementally\n",
    "extended with new features as business needs change."
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7093658,
     "sourceId": 11339021,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 151.535814,
   "end_time": "2025-04-12T20:47:04.395998",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-12T20:44:32.860184",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
